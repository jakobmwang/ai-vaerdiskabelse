# Datainfrastruktur

Databaser og søgemaskiner er ikke en ny opfindelse. De fleste af os har brugt dem i årevis på den ene eller anden måde. Og kløgtige forskere har løbende opfundet nye metoder og systemer til at tilrettelægge data på måder, så de bliver lettere tilgængelige. Man taler om at _indeksere_ data.

Med sprogmodellernes indtog, har vi mere brug for disse metoder end nogensinde, og vi har brug for yderligere metoder til at kunne fastslå, hvornår den ene metode er bedre end den anden.

For hvor du let kan sætte resultaterne af et opslag eller en søgning i den rette kontekst, der måske implicit omfatter formål, delmål, eksterne bindinger, noget du læste i går, og erfaring fra sidst du slog op i databasen, ja, så kniber det for en sprogmodel. Den har brug for det hele eksplicit, hvis du vil være sikker på, at dens svar og handlinger afspejler det. Ellers genererer den det næste ord på baggrund af den mest sandsynlige kontekst, der er indlejret i den fra dens træning.

Desuden tænker vi slet ikke over mange af de signaler, vi får, når vi søger information. Fx er et link fra én side til en anden et signal om en forbindelse, og teksten omkring linket er en kontekst, der signalerer forbindelsens art. Er det en semantisk forbindelse (_Læs mere her_)? Eller er det en finansiel (_Køb nu_)? Eller er den obligatorisk, men irrelevant (_Cookiepolitik_)?

![Hvordan vi ser det vs. hvordan systemet ser det (uden hjælp)](figures/hvordan_vi_ser_det.png)

Bla bla.
